---
title: "WQX Data Portal Exploration "
author: "Badhia Yunes Katz"
date: "January 2025"
# output: rmarkdown::github_document
---


```{r include=FALSE}
library(tidyverse)
library(dataRetrieval)
library(leaflet)
library(janitor)
library(dplyr)
library(ggplot2)
library(DT)         
library(tidyr)
library(scales)
```

## Overview {.tabset}

The goal of this markdown is to see where in the Klamath basin, and what type of data is available from the [WQX portal](https://www.waterqualitydata.us/). The available databases on WQX are NWIS (USGS) and WQX(EPA). WQX is a data warehouse for water quality, biological, and physical data used by state environmental agencies, the EPA, other federal agencies, universities, private citizens, and others.


We are using two dataRetrival functions, `whatWQPsites` and `readWQPdata`

Detailed information about fields metadata can be found [here](https://www.waterqualitydata.us/portal_userguide/)

### whatWQPsites

The following function returns sites that have collected data in the Klamath Basin. Below, is an overview of the column names of the data request are shown.

  * column names of site/station information

```{r, echo=FALSE}
# Here's an example of how we can do the data overview per parameter (?)

# this could serve as an overview of what fields are included when pulling (1) site data and (2) actual data pull
huc_code <- "180102"
# characteristic_name <- "Temperature, water"
start_date <- "2024-01-01"  
end_date <- "2024-12-31"    

# (1) station/site information 
stations <- whatWQPsites(huc = huc_code)
colnames(stations)
```

### readWQPdata

Imports data from Water Quality Portal web service.

 * List of column names:

```{r, echo=FALSE}
# (2) actual water temperature data for the 10 year period
temperature_data <- readWQPdata(
  huc = huc_code,
  startDateLo = start_date,
  startDateHi = end_date
)
colnames(temperature_data)
```

### Monitoring Sites

This table shows all the monitoring sites available across the Klamath Basin

```{r, echo=FALSE, warning=FALSE}
# Retrieve available monitoring sites in the Klamath Basin (HUC: 180102)
klamath_sites <- whatWQPsites(huc = "180102")

# Preview site data
DT::datatable(klamath_sites, options = list(pageLength = 10))
```

Monitoring sites plot 

```{r, echo=FALSE, warning=FALSE}
# monitoring sites plot
color_palette <- colorFactor(
  palette = "Set1", 
  domain = klamath_sites$OrganizationFormalName
)
org_names <- unique(klamath_sites$OrganizationFormalName)

legend_html <- paste0(
  "<div style='background-color:white; padding:4px; font-size:10px; 
               border-radius:5px; width:180px; max-height:200px; overflow:auto;'>",
  "<b>Organization Name</b><br>",
  paste0("<span style='display:inline-block; width:8px; height:8px; background:", 
         color_palette(org_names), 
         "; margin-right:4px;'></span> ", 
         org_names, collapse = "<br>"),
  "</div>"
)

# Create Leaflet map
leaflet(data = klamath_sites |> 
          mutate(longitude = as.numeric(LongitudeMeasure),
                 latitude = as.numeric(LatitudeMeasure))) |> 
  addTiles() |> 
  addCircleMarkers(
    ~longitude, ~latitude,
    popup = ~paste0("<br><b>Organization Name: </b>", OrganizationFormalName,
                    "<br><b>Monitoring Location Identifier: </b>", MonitoringLocationIdentifier,
                    "<br><b>Provider Name: </b>", ProviderName),
    fillOpacity = 0.7,
    radius = 5,
    color = ~color_palette(OrganizationFormalName)
  ) |> 
  addControl(legend_html, position = "bottomright")  
```

Summary of sites by monitoring location type (`MonitoringLocationTypeName`: The descriptive name for a type of monitoring location)

```{r echo=FALSE}
# Summary of sites by type
site_summary <- klamath_sites |> 
  group_by(MonitoringLocationTypeName) |> 
  summarise(Site_Count = n(), .groups = "drop")

DT::datatable(site_summary, options = list(pageLength = 10))
```

Summary: Total number of records per organization

```{r echo=FALSE}
klamath_data_summary <- whatWQPdata(huc = "180102")

# Total number of records per organization
org_summary <- klamath_data_summary |> 
  group_by(OrganizationFormalName) |> 
  summarise(Total_Results = sum(resultCount, na.rm = TRUE), .groups = "drop")

DT::datatable(org_summary, options = list(pageLength = 10))
```

Summary: The top 50 Monitoring locations with the most data entries

```{r echo=FALSE}
# Monitoring locations with the most data
site_data_summary <- klamath_data_summary |> 
  select(MonitoringLocationName, resultCount) |> 
  arrange(desc(resultCount))

DT::datatable(head(site_data_summary, 50), options = list(pageLength = 10))
```



```{r include=FALSE}
# # Get data from the last 10 years (instead of 3)
start_date <- as.character(Sys.Date() - years(10))

# # Select the top 20 sites based on result count
top_sites <- klamath_data_summary |>
  arrange(desc(resultCount)) |>
  head(20) |>
  pull(MonitoringLocationIdentifier)
# 
# # Pick the first site to test
# test_site <- top_sites[1]
# 
# # Run test query
# test_data <- readWQPdata(
#   siteid = test_site,
#   startDateLo = start_date
# )
# 
# # Check if test site returned data
# if (nrow(test_data) == 0) {
#   message("Test site returned no data. Consider changing sites or increasing the timeframe.")
# } else {
#   DT::datatable(head(test_data, 10), options = list(pageLength = 10))
# }
# 
# 
# 
# # Retrieve data for the top 20 sites within the last 10 years
# klamath_sample_data <- readWQPdata(
#   siteid = top_sites,
#   startDateLo = start_date
# )
# 
# # Check if data was retrieved successfully
# if (nrow(klamath_sample_data) == 0) {
#   message("No data found for the selected sites. Consider further increasing the date range or filtering by parameter.")
# } else {
#   DT::datatable(head(klamath_sample_data, 10), options = list(pageLength = 10))
# }
```



```{r include=FALSE}
# Summary per data provider: showing the top 10 providers with the most data
# Find which providers have the most data
provider_summary <- klamath_data_summary |> 
  count(ProviderName, sort = TRUE)

DT::datatable(provider_summary, options = list(pageLength = 10)) #TODO still need to refine this plot idea
```

```{r include=FALSE}
# ggplot(klamath_data_summary, aes(x = MonitoringLocationTypeName, y = resultCount)) +
#   geom_col(fill = "steelblue") +
#   labs(title = "Data Availability by Monitoring Location Type",
#        x = "Monitoring Location Type",
#        y = "Total Number of Results") +
#   theme_minimal() +
#   coord_flip()
```

### Parameters

These are the water quality parameters available (pulling 2020 - 2024 data to view parameters). Parameters of interest will be explored on separate tabs 

```{r echo=FALSE}
# Get metadata for all water quality data available for the specified HUC
wqp_metadata <- readWQPdata(huc = huc_code, startDateLo = "2020-01-01",
  startDateHi = "2024-12-31")

characteristic_names_df <- tibble(CharacteristicName = sort(unique(wqp_metadata$CharacteristicName)))

# Display as an interactive datatable
DT::datatable(characteristic_names_df, options = list(pageLength = 15))
```

### Temperature

Glimpse of temperature data pull 

```{r echo=FALSE}
# col_select <- function(data) {
#   data |> 
#     janitor::clean_names() 
#     select(organization_identifier,
#            organization_formal_name,
#            activity_media_name,
#            activity_media_subdivision_name,
#            activity_start_date,
#            activity_start_time_time,
#            activity_start_time_time_zone_code,
#            activity_end_date,
#            activity_end_time_time,
#            activity_end_time_time_zone_code,
#            monitoring_location_identifier,
#            characteristic_name,
#            result_sample_fraction_text,
#            result_measure_value,
#            result_measure_measure_unit_code,
#            result_status_identifier,
#            result_analytical_method_method_name,
#            provider_name)
# }
# 
# storet_query <- list(
#   huc = huc_code,                       
#   characteristicName = "Temperature, water",
#   startDateLo = "2024-01-01",               
#   startDateHi = Sys.Date()                  
# )

temp_data <- readWQPdata(huc = huc_code,                       
  characteristicName = "Temperature, water",
  startDateLo = "2024-01-01",               
  startDateHi = Sys.Date()) |> 
  janitor::clean_names() 
  # select(organization_identifier,
  #          organization_formal_name,
  #          activity_media_name,
  #          activity_media_subdivision_name,
  #          activity_start_date,
  #          activity_start_time_time,
  #          activity_start_time_time_zone_code,
  #          activity_end_date,
  #          activity_end_time_time,
  #          activity_end_time_time_zone_code,
  #          monitoring_location_identifier,
  #          characteristic_name,
  #          result_sample_fraction_text,
  #          result_measure_value,
  #          result_measure_measure_unit_code,
  #          result_status_identifier,
  #          result_analytical_method_method_name,
  #          provider_name)


temp_data |> glimpse()
```

```{r include=FALSE}
#check that it is only temp data 
unique(temp_data$characteristic_name)
```

Glimpse of station data pull

```{r echo=FALSE}
# get lat/longs
url_call <- paste0('https://www.waterqualitydata.us/Result/search?huc=', huc_code, '&mimeType=tsv&sorted=no')

url_station <- gsub("/Result/", "/Station/", url_call)

site_info <- importWQP(url_station, FALSE, tz="") |>
  janitor::clean_names() |> glimpse()
  # select(monitoring_location_identifier, huc_eight_digit_code, latitude_measure, longitude_measure)
```


```{r include=FALSE}
# join 
all_temp_data <- temp_data |> left_join(site_info) |> 
  mutate(latitude_measure = as.numeric(latitude_measure),
         longitude_measure = as.numeric(longitude_measure)) |> 
  glimpse()
```


Looking how many data entries there are for each day in 2024 

```{r echo=FALSE}
# Count number of records per date
daily_record_counts <- all_temp_data |> 
  group_by(activity_start_date) |> 
  summarise(record_count = n(), .groups = "drop") |> 
  mutate(year = year(activity_start_date),
         month = month(activity_start_date, label = TRUE),
         day = day(activity_start_date))

daily_record_counts_table <- daily_record_counts |> 
  select(activity_start_date, record_count)

DT::datatable(daily_record_counts_table, options = list(pageLength = 10))
```

Plot below shows the same data than table. This indicates that data is not being collected every day

```{r echo=FALSE, warning=FALSE}
# Create a complete reference dataset with all days (1–30) for each month
all_days <- expand.grid(
  day = 1:30, 
  month = unique(daily_record_counts$month),  
  year = unique(daily_record_counts$year)    
)

# Merge with actual data, filling missing values with 0
daily_record_counts <- all_days |> 
  left_join(daily_record_counts, by = c("year", "month", "day")) |> 
  replace_na(list(record_count = 0))  

# Create the plot
ggplot(daily_record_counts, aes(x = day, y = record_count)) +
  geom_col(fill = "steelblue") +
  facet_wrap(~month) +  
  scale_x_continuous(breaks = seq(1, 30, by = 5), limits = c(1, 30)) +  
  labs(title = "Number of Water Temperature Records per Day in 2014",
       x = "Day of the Month",
       y = "Record Count") +
  theme_minimal()

```



```{r echo=FALSE}
# Plot below shows the amount of data entries per site, per month - decided to not add plot below since it is only 2014
# monthly_record_counts_persite <- all_temp_data |> 
#   mutate(
#     year = year(activity_start_date),
#     month = month(activity_start_date, label = TRUE)  
#   ) |> 
#   group_by(year, month, monitoring_location_identifier) |>
#   summarise(record_count = n(), .groups = "drop")
# 
# # Create the plot
# ggplot(monthly_record_counts_persite, aes(x = month, y = record_count)) +
#   geom_col(fill = "steelblue") +
#   facet_wrap(~monitoring_location_identifier, scales = "free_y") +  
#   scale_x_discrete() + 
#   scale_y_continuous(breaks = seq(1, max(monthly_record_counts_persite$record_count, na.rm = TRUE), by = 5)) +  
#   labs(title = "Total Records Per Month for Each Monitoring Location",
#        x = "Month",
#        y = "Record Count") +
#   theme_minimal() +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Temperature from 2020 to 2025

```{r echo=FALSE, warning=FALSE}
temp_data_2020_2025 <- readWQPdata(huc = huc_code,                       
  characteristicName = "Temperature, water",
  startDateLo = "2020-01-01",               
  startDateHi = Sys.Date()) |> 
  janitor::clean_names() |> 
  select(organization_identifier,
           organization_formal_name,
           activity_media_name,
           activity_media_subdivision_name,
           activity_start_date,
           activity_start_time_time,
           activity_start_time_time_zone_code,
           activity_end_date,
           activity_end_time_time,
           activity_end_time_time_zone_code,
           monitoring_location_identifier,
           characteristic_name,
           result_sample_fraction_text,
           result_measure_value,
           result_measure_measure_unit_code,
           result_status_identifier,
           result_analytical_method_method_name,
           provider_name)

daily_temp_2020_2025 <- temp_data_2020_2025 |> 
  group_by(activity_start_date) |> 
  summarise(record_count = n(), .groups = "drop") |> 
  mutate(year = year(activity_start_date),
         month = month(activity_start_date, label = TRUE),
         day = day(activity_start_date))

ggplot(daily_temp_2020_2025, aes(x = day, y = record_count)) +
  geom_col(fill = "steelblue") +
  facet_wrap(~month) +  
  scale_x_continuous(breaks = seq(1, 30, by = 5), limits = c(1, 30)) +  
  labs(title = "Number of Water Temperature Records per Day between 2020 and 2025",
       x = "Day of the Month",
       y = "Record Count") +
  theme_minimal()

```

Map below shows where monitoring locations are, and what agency is monitoring/maintain it

```{r, echo=FALSE, warning=FALSE}
# Define color palette
color_palette <- colorFactor(topo.colors(length(unique(temp_data_2020_2025$organization_formal_name))), 
                             domain = temp_data_2020_2025$organization_formal_name)

all_2020_2025_temp_data <- temp_data_2020_2025 |> left_join(site_info) |> 
  mutate(latitude_measure = as.numeric(latitude_measure),
         longitude_measure = as.numeric(longitude_measure))

# Create Leaflet map
leaflet(data = all_2020_2025_temp_data) |> 
  addTiles() |> 
  addCircleMarkers(
    ~longitude_measure, ~latitude_measure,
    popup = ~paste0("<br><b>Monitoring Location: </b>", monitoring_location_name,
                    "<br><b>Monitoring Location Type: </b>", monitoring_location_type_name,
                    "<br><b>Characteristic Name: </b>", characteristic_name),
    color = ~color_palette(organization_formal_name),
    fillOpacity = 0.7,
    radius = 5
  ) |> 
  addLegend(
    position = "bottomright",  
    pal = color_palette,  
    values = ~organization_formal_name,  
    title = "Organization Name",  
    opacity = 1
  )
```

Table below shows the amount of data entries per site, per year and month

```{r echo=FALSE}
# Table below shows the amount of data entries per site, per month
monthly_record_counts_persite <- all_2020_2025_temp_data |>
  mutate(
    year = year(activity_start_date),
    month = month(activity_start_date, label = TRUE)
  ) |>
  group_by(year, month, monitoring_location_identifier) |>
  summarise(record_count = n(), .groups = "drop")

monthly_record_counts_persite_table <- monthly_record_counts_persite |> 
  select(monitoring_location_identifier, record_count, year, month)

DT::datatable(monthly_record_counts_persite_table, options = list(pageLength = 10))
```


Table below shows the amount of data entries per site, per year (note that this is per each site)

```{r echo=FALSE}
# Table below shows the amount of data entries per site, per month
yearly_record_counts_persite <- all_2020_2025_temp_data |>
  mutate(
    year = year(activity_start_date),
    month = month(activity_start_date, label = TRUE)
  ) |>
  group_by(year, monitoring_location_identifier) |>
  summarise(record_count = n(), .groups = "drop")

yearly_record_counts_persite_table <- yearly_record_counts_persite |> 
  select(monitoring_location_identifier, record_count, year)

DT::datatable(yearly_record_counts_persite_table, options = list(pageLength = 10))
```

Table plot below shows the amount of data entries per organization, per year (note that this is per each organization, which includes all monitoring stations managed by them)

```{r echo=FALSE}
# Extract year for faceting
temp_data_2020_2025 <- temp_data_2020_2025 |> mutate(year = year(activity_start_date))


yearly_summary_temp <- temp_data_2020_2025 |> 
    group_by(organization_identifier) |> 
    summarize(year = year,
              total_records = n(),
              .groups = "drop")

ggplot(yearly_summary_temp, aes(x = organization_identifier, y = total_records, fill = organization_identifier)) +
  geom_bar(stat = "identity") +
  facet_wrap(~year, scales = "free_y") +  
  theme_minimal() +
  labs(
    title = "Total Water Temperature Records by Organization for Each Year",
    x = "Organization Identifier",
    y = "Total Records"
  ) +
    theme(
    axis.text.x = element_text(angle = 90, hjust = 1, size = 8),  
    legend.text = element_text(size = 8), 
    legend.title = element_text(size = 10),  
    legend.key.size = unit(0.5, "cm")
  )

```

```{r echo=FALSE, warning=FALSE}
# Ensure date is properly formatted
temp <- temp_data_2020_2025 |> mutate(activity_start_date = as.Date(activity_start_date),
                       result_measure_value = as.numeric(result_measure_value))

summary(temp$result_measure_value)
temp <- temp |> filter(!is.na(result_measure_value))

ggplot(temp, aes(x = activity_start_date, y = result_measure_value)) +
  geom_point(alpha = 0.5, size = 1) + 
  facet_wrap(~organization_formal_name, scales = "free_y") +  
  scale_y_continuous(breaks = pretty_breaks(n = 5)) +  
  labs(title = "Water Temperature Over Time by Agency (2020-2024)",
       x = "Date",
       y = "Temperature (°C)") +
  theme_minimal() +
  theme(
    legend.position = "none", 
    axis.text.x = element_text(angle = 45, hjust = 1),  
    axis.text.y = element_text(size = 8)  
  )

```

### Dissolved oxygen (DO)

Glimpse of dissolved oxygen data pull 

```{r echo=FALSE}
do_data <- readWQPdata(huc = huc_code,                       
  characteristicName = "Dissolved oxygen (DO)",
  startDateLo = "2020-01-01",               
  startDateHi = Sys.Date()) |> 
  janitor::clean_names()

glimpse(do_data)
```

```{r include=FALSE}
#check that it is only temp data 
unique(do_data$characteristic_name)
```


```{r include=FALSE}
# join 
all_do_data <- do_data |> left_join(site_info) |> 
  mutate(latitude_measure = as.numeric(latitude_measure),
         longitude_measure = as.numeric(longitude_measure)) |> 
  glimpse()
```


Looking how many data entries there are for each day from 2020 to today 

```{r echo=FALSE}
# Count number of records per date
daily_do_record_counts <- all_do_data |> 
  group_by(activity_start_date) |> 
  summarise(record_count = n(), .groups = "drop") |> 
  mutate(year = year(activity_start_date),
         month = month(activity_start_date, label = TRUE),
         day = day(activity_start_date))

daily_do_record_counts_table <- daily_do_record_counts |> 
  select(activity_start_date, record_count)

DT::datatable(daily_do_record_counts_table, options = list(pageLength = 10))
```

Plot below shows the same data than table. This indicates that data is not being collected every day

```{r echo=FALSE, warning=FALSE}

# Create the plot
ggplot(daily_do_record_counts, aes(x = day, y = record_count)) +
  geom_col(fill = "steelblue") +
  facet_wrap(~month) +  
  scale_x_continuous(breaks = seq(1, 30, by = 5), limits = c(1, 30)) +  
  labs(title = "Number of DO Records per Day (2020 - 2024)",
       x = "Day of the Month",
       y = "Record Count") +
  theme_minimal()

```

Map below shows where monitoring locations are, and what agency is monitoring/maintain it

```{r, echo=FALSE, warning=FALSE}

# Create Leaflet map
leaflet(data = all_do_data) |> 
  addTiles() |> 
  addCircleMarkers(
    ~longitude_measure, ~latitude_measure,
    popup = ~paste0("<br><b>Monitoring Location: </b>", monitoring_location_name,
                    "<br><b>Monitoring Location Type: </b>", monitoring_location_type_name,
                    "<br><b>Characteristic Name: </b>", characteristic_name),
    color = ~color_palette(organization_formal_name),
    fillOpacity = 0.7,
    radius = 5
  ) |> 
  addLegend(
    position = "bottomright",  
    pal = color_palette,  
    values = ~organization_formal_name,  
    title = "Organization Name",  
    opacity = 1
  )
```

Table below shows the amount of data entries per site, per year and month

```{r echo=FALSE}
monthly_do_record_counts_persite <- all_do_data |>
  mutate(
    year = year(activity_start_date),
    month = month(activity_start_date, label = TRUE)
  ) |>
  group_by(year, month, monitoring_location_identifier) |>
  summarise(record_count = n(), .groups = "drop")

monthly_record_counts_persite_table <- monthly_record_counts_persite |> 
  select(monitoring_location_identifier, record_count, year, month)

DT::datatable(monthly_record_counts_persite_table, options = list(pageLength = 10))
```

Table below shows the amount of data entries per site, per year (note that this is per each site)

```{r echo=FALSE}
# Table below shows the amount of data entries per site, per month
yearly_do_record_counts_persite <- all_do_data |>
  mutate(
    year = year(activity_start_date),
    month = month(activity_start_date, label = TRUE)
  ) |>
  group_by(year, monitoring_location_identifier) |>
  summarise(record_count = n(), .groups = "drop")

yearly_do_record_counts_persite_table <- yearly_do_record_counts_persite |> 
  select(monitoring_location_identifier, record_count, year)

DT::datatable(yearly_do_record_counts_persite_table, options = list(pageLength = 10))
```

Table plot below shows the amount of data entries per organization, per year (note that this is per each organization, which includes all monitoring stations managed by them)

```{r echo=FALSE}
# Extract year for faceting
all_do_data <- all_do_data |> mutate(year = year(activity_start_date))


yearly_summary_do <- all_do_data |> 
    group_by(organization_identifier) |> 
    summarize(year = year,
              total_records = n(),
              .groups = "drop")

ggplot(yearly_summary_do, aes(x = organization_identifier, y = total_records, fill = organization_identifier)) +
  geom_bar(stat = "identity") +
  facet_wrap(~year, scales = "free_y") +  
  theme_minimal() +
  labs(
    title = "Total DO Records by Organization for Each Year",
    x = "Organization Identifier",
    y = "Total Records"
  ) +
    theme(
    axis.text.x = element_text(angle = 90, hjust = 1, size = 8),  
    legend.text = element_text(size = 8), 
    legend.title = element_text(size = 10),  
    legend.key.size = unit(0.5, "cm")
  )

```


```{r echo=FALSE, warning=FALSE}
# Ensure date is properly formatted
do_data <- all_do_data |> mutate(activity_start_date = as.Date(activity_start_date),
                       result_measure_value = as.numeric(result_measure_value))

summary(do_data$result_measure_value)
do_data <- do_data |> filter(!is.na(result_measure_value))

ggplot(do_data, aes(x = activity_start_date, y = result_measure_value)) +
  geom_point(alpha = 0.5, size = 1) + 
  facet_wrap(~organization_formal_name, scales = "free_y") +  
  scale_y_continuous(breaks = pretty_breaks(n = 5)) +  
  labs(title = "DO Over Time by Agency (2020-2024)",
       x = "Date",
       y = "Dissolved Oxygen (DO)") +
  theme_minimal() +
  theme(
    legend.position = "none", 
    axis.text.x = element_text(angle = 45, hjust = 1),  
    axis.text.y = element_text(size = 8)  
  )

```
